<hr>

<h3 class="company first-color">Yahoo! Cluster Management</h3>

<table cellspacing="0">


   <tr>
		<td class="second-color"> Dates: </td>


<td> <i> Dec 2009 - Oct 2010 </i> </td>

	</tr>
 



   <tr>
		<td class="second-color"> Role: </td>

   	<td> <i> Senior Technical Yahoo! </i> </td>
   </tr>



   <tr>
		<td class="second-color"> Technologies: </td>	
		<td> <i> zookeeper </i> </td>
	</tr>



   <tr>
		<td class="second-color">Programming Languages: </td>

		<td> <i> java, perl, tla+ </i></td>
	</tr>
 



</table>

<h4 class="project-item third-color">
	<i>Objectives</i>
</h4>

<div class="project-item-detail">
	<p>Support auto configuration and provisioning of cluster hosts using a distributed agent architecture.  Auto configure new machines via PXE boot.   Self register to a zookeeper cluster in order to publish status and to receive provisioning and management operations.  </p>
</div><h4 class="project-item third-color">
	<i>Responsibilites</i>
</h4>

<div class="project-item-detail">
	<p>I was responsible for writing the endpoint agent which received and implemented the command sets to manage traffic, image deployment, application control and diagnostics.  </p>
</div><h4 class="project-item third-color">
	<i>Key Challenges</i>
</h4>

<div class="project-item-detail">
	<p>The system was designed to support several deployment scenarios:</p>
	<ul><li>	Clean Installation</li>
	<li>	Replacement upgrade</li></ul>
	<blockquote>⁃	Deploy a new tier with the desired capacity and configurations</blockquote>
	<blockquote>⁃	Cut-over to the new tier and release resources on the deprecated tier</blockquote>
	<blockquote>⁃	Return deprecated hardware to the machine pool</blockquote>
	<ul><li>	Rolling upgrade</li></ul>
	<blockquote>⁃	Remove a subset of machines from active serving in the tier and upgrade</blockquote>
	<blockquote>⁃	Enable newly provisioned machines and repeat sequence until all machines are upgraded</blockquote>
	<ul><li>	Deploy new services</li></ul>
	<blockquote>⁃	In some cases the architecture will change and the upgrade is more  accurately described as shifting traffic to a new service. This can be viewed as an extreme case of the Replacement case, in that Replacement is really a per Tier concept, whereas this upgrade is on a Service as a whole.</blockquote>
	<ul><li>	Break/Fix</li></ul>
	<blockquote>⁃	Automated provisioning of hardware to replace broken hardware, subject to security and rate-limiting.</blockquote>
	<ul><li>	Exceptions/Rollback</li></ul>
	<blockquote>⁃	In the case where some error occurs during or after the upgrade, the SE determines:</blockquote>
	<blockquote>1)	Whether the error is systemic across the tier(s). If it is, the whole deployment is rolled back.  </blockquote>
	<blockquote>2)	Whether the error affects isolated hosts. If so the SE determines whether to take the hosts out of rotation, which would occur if the number affected is small, or roll back if the number affected is large. (Except in the case of hardware failure, such failures indicate a failure on the part of the CSI to uniformly deploy. Nonetheless, we should provide a means of dealing with the case.)</blockquote>

</div><h4 class="project-item third-color">
	<i>Technical Details</i>
</h4>

<div class="project-item-detail">
	<p>Machines booted via PXE and installed a remote agent.  This agent would manage multiple virtual environments configured as chroot jails.  Additional Yahoo proprietary virtualization and package managers were incorporated into the base-builds.</p>
<p>Zookeeper was used as the controller.  The implementation needed to support the following scenarios</p>

	<blockquote>1)	provide a persistent store of configuration information</blockquote>
	<blockquote>2)	provide a reliable means of signaling state change information to trigger deployments</blockquote>
	<blockquote>3)	provide a reliable means of signalaing success or failure of a requested operation</blockquote>
	<blockquote>4)	provide a means to indicate the completion of a set of work</blockquote>
	<blockquote>5)	handle cases of incremental node addition</blockquote>
	<blockquote>6)	prove that the routine always ends up in a completed state [ i.e. no more work in progress ]</blockquote>
	<blockquote>7)	provide an audit trail for a given node configuration - i.e. log the set of ip addresses for auditing purposes.</blockquote>
</div><h4 class="project-item third-color">
	<i>Project Deliverables</i>
</h4>

<div class="project-item-detail">
	<p>A working implementation of the endpoint agent was delivered.</p>
</div><h4 class="project-item third-color">
	<i>Supplementary Details</i>
</h4>

<div class="project-item-detail">
	<p>The PXE Client/Server environment was designed so it can be seamlessly integrated with an already in place DHCP and TFTP server infrastructure. This design goal presented a challenge when dealing with the classic DHCP protocol. Corporate DHCP servers are usually subject to strict policies that are designed to prevent easily adding the additional parameters and rules required to support a PXE environment. For this reason the PXE standard developed the concept of DHCP redirection or "proxyDHCP". The idea behind a proxyDHCP is to split the PXE DHCP requirements in two independently run and administered server units:</p>
<p>The classic DHCP server providing IP address, IP mask, etc. to all booting DHCP clients.</p>
<p>The proxyDHCP server providing TFTP server IP address and name of the NBP only to PXE identified booting clients.</p>

<p>
<img src="Yahoo_Cluster_Management/Supplementary_Details.jpg" alt="" >
</p>

<p>In a DHCP plus proxyDHCP server environment[3]: 18  the PXE client initially broadcasts a single PXE DHCPDISCOVER packet and receives two complementary DHCPOFFERs; one from the regular non PXE enabled DHCP server and a second one from the proxyDHCP server. Both answers together provide the required information to allow the PXE client to continue with its booting process. This non-intrusive approach allows setting a PXE environment without touching the configuration of an already working DHCP server. The proxyDHCP service may also run on the same host as the standard DHCP service but even in this case they are both two independently run and administered applications. Since two services cannot use the same port 67/UDP on the same host, the proxyDHCP runs on port 4011/UDP. The proxyDHCP approach has proved to be extremely useful in a wide range of PXE scenarios going from corporate to home environments.</p>
</div><h4 class="project-item third-color">
	<i>Current State</i>
</h4>

<div class="project-item-detail">
	<p>The service was never deployed and the project was shutdown.</p>
</div><h4 class="project-item">
	<i>Colleagues</i>
</h4>

<table><tr>
	<td>
		Luis Alvez:
	</td>
	<td>
		<a href="https://www.linkedin.com/in/lafaspot/">https://www.linkedin.com/in/lafaspot/</a>
	</td>
</tr>

<tr>
	<td>
		Brian Harrington:
	</td>
	<td>
		<a href="https://www.linkedin.com/in/brharrington/">https://www.linkedin.com/in/brharrington/</a>
	</td>
</tr>

</table>


